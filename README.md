# Reddit Data Collection and Markdown Export

This project provides tools for collecting Reddit posts and comments from specified subreddits and exporting them in Markdown format.

## Scripts Overview

### 1. `fetch_reddit_data.py`

**Purpose:**  
Fetches posts and comments from subreddits listed in `subreddits.txt`, saves each post (with comments) as a JSON file in a date-based folder, and stores all posts and comments in a SQLite database. Handles Reddit API rate limiting, supports configuration via environment variables, and creates an index file summarizing the collected data.

**Features:**

- Reads subreddit names from `subreddits.txt` (ignores comments and blank lines).
- Fetches recent posts from each subreddit (number and sort order configurable).
- Retrieves comments for each post up to a configurable depth.
- Saves each post (with comments) as a JSON file in a date-based folder.
- Stores all posts and comments in a SQLite database (`data/reddit_data.db` by default).
- Creates an `index.json` file summarizing the day's collected data.
- Supports configuration via `.env` file (API limits, folder paths, etc.).
- Handles Reddit API rate limiting with exponential backoff.

**Usage:**

```bash
python fetch_reddit_data.py
```

**Environment Variables (set in `.env`):**

- `REDDIT_USER_AGENT` - User-Agent string for Reddit API requests (required).
- `POSTS_PER_SUBREDDIT` - Number of posts to fetch per subreddit (default: 40).
- `REDDIT_POST_SORT` - Post sorting method: "new", "top", etc. (default: "new").
- `REDDIT_DB_PATH` - Path to SQLite database (default: data/reddit_data.db).
- `TEXT_DATA_FOLDER` - Base folder for saving JSON files (default: text_data).
- `REDDIT_COMMENT_DEPTH` - Max depth for comment fetching (default: 8).

**Outputs:**

- JSON files for each post (with comments) in a dated folder.
- SQLite database with posts and comments.
- `index.json` summarizing the day's collection.

---

### 2. `export_reddit_text.py`

**Purpose:**  
Exports posts and their threaded comments from the SQLite database to a Markdown file, using blockquote indentation to represent comment nesting.

**Features:**

- Connects to the SQLite database created by `fetch_reddit_data.py`.
- Extracts posts and comments within a user-specified date range.
- Outputs data to a Markdown file, with each post as a section and comments shown as indented blockquotes (using `>`).
- Preserves comment threading and author information.
- Supports command-line arguments for date range, output file path, and database path.
- Useful for preparing Reddit data for sharing, documentation, or further Markdown-based processing.

---

### 3. `potential-replies.py`

**Purpose:**  
Analyzes Reddit posts and their comment threads from a local SQLite database, uses LLMs (configured via models.json) to generate high-quality reply suggestions, and outputs a structured plain text file with potential Reddit replies, action points, and data for easy parsing.

**Features:**

- Reads posts and comments from a SQLite database (default: data/reddit_data.db).
- For each post in a specified date range, formats the thread and sends it to an LLM for reply suggestion.
- Outputs a plain text file (default: potential_replies.txt) with structured blocks for each post, including post info, body, comments, and LLM-suggested reply.
- Includes action points and fields for manual review (e.g., MARK_TO_POST, TARGET_PARENT_ID).
- Supports configuration of LLMs via models.json.
- Command-line arguments for date range, output file, database path, and models config.

**Usage:**

```bash
python potential-replies.py START_DATE [END_DATE] [-o OUTPUT_FILE] [--db-path DB_PATH] [--models-json MODELS_JSON]
```

Example:

```bash
python potential-replies.py 2024-05-20 2024-05-21 -o data/potential_replies.txt --db-path data/reddit_data.db --models-json models.json
```

**Environment Variables (set in `.env`):**

- `REDDIT_DB_PATH` - Path to SQLite database (default: data/reddit_data.db).
- `TEXT_DATA_FOLDER` - Base folder for saving output files (default: data).

**Outputs:**

- Plain text file with structured reply suggestions and action blocks for each post.

---

### 4. `post_reddit_replies.py`

**Purpose:**  
Reads a structured plain text file (e.g., potential_replies.txt) generated by potential-replies.py, finds entries marked for posting (MARK_TO_POST is '[x]'), and posts the suggested reply to Reddit using PRAW. Uses the specified TARGET_PARENT_ID (or defaults to the post's ID), and after successful posting, updates the marker to '[p]'. Reddit API credentials are loaded from .env.

**Features:**

- Reads a plain text file with structured reply suggestions and action blocks.
- Finds entries marked for posting and posts replies to Reddit (to posts or comments).
- Uses PRAW for Reddit API interaction, with credentials loaded from .env.
- Updates the marker in the text file after successful posting.
- Supports configurable file locations and delays between posts.

**Usage:**

```bash
python post_reddit_replies.py
```

**Environment Variables (set in `.env`):**

- `REDDIT_CLIENT_ID` - Reddit API client ID.
- `REDDIT_CLIENT_SECRET` - Reddit API client secret.
- `REDDIT_USER_AGENT` - User-Agent string for Reddit API requests.
- `REDDIT_USERNAME` - Reddit username.
- `REDDIT_PASSWORD` - Reddit password.
- `TEXT_DATA_FOLDER` - Base folder for saving output files (default: data).

**Outputs:**

- Posts replies to Reddit for marked entries.
- Updates the plain text file to mark posted replies.

---

## Typical Workflow

1. **Collect Data:**  
   Run `fetch_reddit_data.py` to gather Reddit posts and comments from your target subreddits.

2. **Export Data:**  
   Use `export_reddit_text.py` to extract and format the collected data as Markdown.

## Requirements

- Python 3.6+
- Dependencies listed in `requirements.txt`
- Reddit API access (no authentication required for public data, but user-agent is required)

## Configuration

Use the `.env` file to set environment variables such as:

- `REDDIT_USER_AGENT`
- `POSTS_PER_SUBREDDIT`
- `REDDIT_POST_SORT`
- `REDDIT_DB_PATH`
- `TEXT_DATA_FOLDER`
- `REDDIT_COMMENT_DEPTH`

## License

See `LICENSE` file if present.
